{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ca31113",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ca84ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked', 'train_test'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Creating a concatenated dataset of both training and test data\n",
    "training['train_test'] = 1 # indicates that it is training data\n",
    "test['train_test'] = 0 # indicates that it is test data\n",
    "test['Survived'] = np.NaN # filling in the column of Survived for test data as NaN because we don't know this \n",
    "all_data = pd.concat([training, test])\n",
    "all_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cf4850",
   "metadata": {},
   "source": [
    "## Project Planning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc22a6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# understanding the nature of the data .info() .describe()\n",
    "# histograms and boxplots \n",
    "# value counts \n",
    "# missing data (remove or impute missing data)\n",
    "# correlation between the metrics \n",
    "# explore interesting themes:\n",
    "    # do the wealthy survive\n",
    "    # by location i.e. the cabin they were in \n",
    "    # age scatterplot with ticket price \n",
    "    # a young and wealthy variable?\n",
    "    # total spent \n",
    "# feature engineering - important, one of the things that could improve accuracy\n",
    "# preprocess data together or use a transformer?\n",
    "    # use label for training and test\n",
    "# scaling? \n",
    "\n",
    "# model baseline \n",
    "# model comparison with CV "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d6c809",
   "metadata": {},
   "source": [
    "## Understanding the Nature of the Data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a0d9ef",
   "metadata": {},
   "source": [
    "For numeric data: \n",
    "- histograms to understand the correlation\n",
    "- Correlation plots\n",
    "- Pivot table to compare the survival rate across numeric variables\n",
    "\n",
    "For categorical data: \n",
    "- made bar charts to understand the balance of classes\n",
    "- made pivot tables to understand relationship wtih survival "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab7f627d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 13 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      " 12  train_test   891 non-null    int64  \n",
      "dtypes: float64(2), int64(6), object(5)\n",
      "memory usage: 90.6+ KB\n"
     ]
    }
   ],
   "source": [
    "training.info() # allows us to look at our data types and null counts of each "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3568229",
   "metadata": {},
   "source": [
    "We see that age and cabin both have a significant amount of null counts, so we need to think about how to manage that. We als osee that embarked has 2 null values. Next we can take a look at the numeric data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddd84b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>train_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  train_test  \n",
       "count  891.000000  891.000000       891.0  \n",
       "mean     0.381594   32.204208         1.0  \n",
       "std      0.806057   49.693429         0.0  \n",
       "min      0.000000    0.000000         1.0  \n",
       "25%      0.000000    7.910400         1.0  \n",
       "50%      0.000000   14.454200         1.0  \n",
       "75%      0.000000   31.000000         1.0  \n",
       "max      6.000000  512.329200         1.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.describe() # describe function allows us to better understand the numeric data (i.e. mean, std, central tendencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3872dd64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare',\n",
       "       'train_test'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.describe().columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "199d1f80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAASnUlEQVR4nO3dX4wdZ3nH8e8PGwKEoCTNxnVttw6tlTahIqFbUxQJtZg2pgHsi6YyEshCqdwLQ0FFQjaqSrmwlJsiKrVBtRJgKRTXDU1jBQoYQ0SpSswGQsFx3JjExFsbe/lXCNAgm6cXO2lP7F3v8e7ZHO+b70eyZuY578w848S/Hb/nnHGqCklSW5417AYkSYNnuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl+YpyV8k+fCw+5B6Ge5qXpIjSX6S5PEkJ5J8IMkLht2XtJAMdz1TvLaqXgC8FPhN4M/63TFT/LOiRcX/YfWMUlX/BfwL8OtJ7kkymeR73frKJ8cluTfJjiT/BvwYeFGSa5PsTfLd7m8A7+w59HOSfCjJD5McSDL6NF+a9BSGu55RkqwCfh94BPgA8EvALwI/Af76jOFvBLYAlwAngM8AnwR+AfgVYF/P2NcBu4BLgT3THEt6Wi0ddgPS0+Sfk5wC/hv4OPCOqvrJky8m2QF87ox9PlhVB7rXXwN8q6r+snvtf4D7esZ+oao+0Y39O+BtC3IVUp8Mdz1TbKyqzzy5keT5Sf4WWA9c1pUvSbKkqk5320d79l8FfOMcx/9Wz/qPgecmWVpVpwbQu3TenJbRM9XbgauBl1XVC4FXdPX0jOl9ZOpR4Jefpt6keTPc9Ux1CVPz7N9PcjnwrlnG3wP8fJK3JbkoySVJXrbgXUpzZLjrmeq9wPOAbwNfZOqN0hlV1Q+B3wVey9QUzMPA7yxsi9LcxX+sQ5La4527JDXIcJekBhnuktQgw12SGnRBfInpiiuuqNWrVw+7DUlaVO6///5vV9XIdK/NGu5Jrgb+oaf0IuDPgQ919dXAEeAPq+p73T7bgVuA08CfVNWnznWO1atXMz4+PuuFSJL+X5JvzvTarNMyVXWoqq6rquuA32Dqq9V3AduAfVW1hqkHKG3rTnYNsAm4lqmvdt+WZMl8L0KS1L/znXNfB3yjqr4JbADGuvoYsLFb3wDsqqonqupR4DCwdgC9SpL6dL7hvgn4aLe+rKqOA3TLK7v6Cp76wKWJrvYUSbYkGU8yPjk5eZ5tSJLOpe9wT/Icpp5Z/Y+zDZ2mdtbXYKtqZ1WNVtXoyMi07wdIkubofO7cXw18uapOdNsnkiwH6JYnu/oEU49HfdJK4Nh8G5Uk9e98wv31/P+UDEz9azObu/XNwN099U3dk/OuAtYA++fbqCSpf319zj3J85l6It4f95RvBXYnuQV4DLgZoKoOJNkNPAicArb2/OMHkqSnQV/hXlU/Bn7ujNp3mPr0zHTjdwA75t2dJGlOfPyAJDXognj8wHyt3vbxoZz3yK03DeW8kjQb79wlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBvUV7kkuTXJnkoeSHEzy8iSXJ9mb5OFueVnP+O1JDic5lOTGhWtfkjSdfu/c/wr4ZFX9KvAS4CCwDdhXVWuAfd02Sa4BNgHXAuuB25IsGXTjkqSZzRruSV4IvAK4A6CqflpV3wc2AGPdsDFgY7e+AdhVVU9U1aPAYWDtYNuWJJ1LP3fuLwImgQ8k+UqS25NcDCyrquMA3fLKbvwK4GjP/hNdTZL0NOkn3JcCLwXeV1XXAz+im4KZQaap1VmDki1JxpOMT05O9tWsJKk//YT7BDBRVfd123cyFfYnkiwH6JYne8av6tl/JXDszINW1c6qGq2q0ZGRkbn2L0maxqzhXlXfAo4muborrQMeBPYAm7vaZuDubn0PsCnJRUmuAtYA+wfatSTpnJb2Oe4twEeSPAd4BHgTUz8Ydie5BXgMuBmgqg4k2c3UD4BTwNaqOj3wziVJM+or3KvqAWB0mpfWzTB+B7Bj7m1JkubDb6hKUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QG9RXuSY4k+VqSB5KMd7XLk+xN8nC3vKxn/PYkh5McSnLjQjUvSZre+dy5/05VXVdVo932NmBfVa0B9nXbJLkG2ARcC6wHbkuyZIA9S5JmMZ9pmQ3AWLc+Bmzsqe+qqieq6lHgMLB2HueRJJ2nfsO9gE8nuT/Jlq62rKqOA3TLK7v6CuBoz74TXe0pkmxJMp5kfHJycm7dS5KmtbTPcTdU1bEkVwJ7kzx0jrGZplZnFap2AjsBRkdHz3pdkjR3fd25V9WxbnkSuIupaZYTSZYDdMuT3fAJYFXP7iuBY4NqWJI0u1nDPcnFSS55ch34PeDrwB5gczdsM3B3t74H2JTkoiRXAWuA/YNuXJI0s36mZZYBdyV5cvzfV9Unk3wJ2J3kFuAx4GaAqjqQZDfwIHAK2FpVpxeke0nStGYN96p6BHjJNPXvAOtm2GcHsGPe3UmS5sRvqEpSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1qO9wT7IkyVeS3NNtX55kb5KHu+VlPWO3Jzmc5FCSGxeicUnSzM7nzv2twMGe7W3AvqpaA+zrtklyDbAJuBZYD9yWZMlg2pUk9aOvcE+yErgJuL2nvAEY69bHgI099V1V9URVPQocBtYOpFtJUl/6vXN/L/AO4Gc9tWVVdRygW17Z1VcAR3vGTXQ1SdLTZNZwT/Ia4GRV3d/nMTNNraY57pYk40nGJycn+zy0JKkf/dy53wC8LskRYBfwyiQfBk4kWQ7QLU924yeAVT37rwSOnXnQqtpZVaNVNToyMjKPS5AknWnWcK+q7VW1sqpWM/VG6Wer6g3AHmBzN2wzcHe3vgfYlOSiJFcBa4D9A+9ckjSjpfPY91Zgd5JbgMeAmwGq6kCS3cCDwClga1WdnnenkqS+nVe4V9W9wL3d+neAdTOM2wHsmGdvkqQ58huqktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQbOGe5LnJtmf5KtJDiR5d1e/PMneJA93y8t69tme5HCSQ0luXMgLkCSdrZ879yeAV1bVS4DrgPVJfgvYBuyrqjXAvm6bJNcAm4BrgfXAbUmWLEDvkqQZzBruNeXxbvPZ3a8CNgBjXX0M2NitbwB2VdUTVfUocBhYO8imJUnn1tece5IlSR4ATgJ7q+o+YFlVHQfolld2w1cAR3t2n+hqZx5zS5LxJOOTk5PzuARJ0pn6CveqOl1V1wErgbVJXnyO4ZnuENMcc2dVjVbV6MjISF/NSpL6c16flqmq7wP3MjWXfiLJcoBuebIbNgGs6tltJXBsvo1KkvrXz6dlRpJc2q0/D3gV8BCwB9jcDdsM3N2t7wE2JbkoyVXAGmD/gPuWJJ3D0j7GLAfGuk+8PAvYXVX3JPl3YHeSW4DHgJsBqupAkt3Ag8ApYGtVnV6Y9iVJ05k13KvqP4Drp6l/B1g3wz47gB3z7k6SNCd+Q1WSGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDVo1nBPsirJ55IcTHIgyVu7+uVJ9iZ5uFte1rPP9iSHkxxKcuNCXoAk6Wz93LmfAt5eVb8G/BawNck1wDZgX1WtAfZ123SvbQKuBdYDtyVZshDNS5KmN2u4V9Xxqvpyt/5D4CCwAtgAjHXDxoCN3foGYFdVPVFVjwKHgbUD7luSdA7nNeeeZDVwPXAfsKyqjsPUDwDgym7YCuBoz24TXe3MY21JMp5kfHJycg6tS5Jm0ne4J3kB8DHgbVX1g3MNnaZWZxWqdlbVaFWNjoyM9NuGJKkPfYV7kmczFewfqap/6sonkizvXl8OnOzqE8Cqnt1XAscG064kqR/9fFomwB3Awap6T89Le4DN3fpm4O6e+qYkFyW5ClgD7B9cy5Kk2SztY8wNwBuBryV5oKu9E7gV2J3kFuAx4GaAqjqQZDfwIFOftNlaVacH3bgkaWazhntVfYHp59EB1s2wzw5gxzz6kiTNg99QlaQGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhrUzz+QrRms3vbxoZz3yK03DeW8khYP79wlqUGzhnuS9yc5meTrPbXLk+xN8nC3vKznte1JDic5lOTGhWpckjSzfu7cPwisP6O2DdhXVWuAfd02Sa4BNgHXdvvclmTJwLqVJPVl1nCvqs8D3z2jvAEY69bHgI099V1V9URVPQocBtYOplVJUr/mOue+rKqOA3TLK7v6CuBoz7iJrnaWJFuSjCcZn5ycnGMbkqTpDPoN1UxTq+kGVtXOqhqtqtGRkZEBtyFJz2xzDfcTSZYDdMuTXX0CWNUzbiVwbO7tSZLmYq7hvgfY3K1vBu7uqW9KclGSq4A1wP75tShJOl+zfokpyUeB3wauSDIBvAu4Fdid5BbgMeBmgKo6kGQ38CBwCthaVacXqHdJ0gxmDfeqev0ML62bYfwOYMd8mpIkzY+PH9B58ZEL0uLg4wckqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGrRg4Z5kfZJDSQ4n2bZQ55EknW3pQhw0yRLgb4DfBSaALyXZU1UPLsT5pIW0etvHh3LeI7feNJTzDpO/14OzIOEOrAUOV9UjAEl2ARsAw13q07CCDtoMu3Np8fc6VTX4gyZ/AKyvqj/qtt8IvKyq3twzZguwpdu8Gjg0j1NeAXx7HvtfKFq5DvBaLkStXAd4LU/6paoame6FhbpzzzS1p/wUqaqdwM6BnCwZr6rRQRxrmFq5DvBaLkStXAd4Lf1YqDdUJ4BVPdsrgWMLdC5J0hkWKty/BKxJclWS5wCbgD0LdC5J0hkWZFqmqk4leTPwKWAJ8P6qOrAQ5+oMZHrnAtDKdYDXciFq5TrAa5nVgryhKkkaLr+hKkkNMtwlqUGLOtxbecRBkvcnOZnk68PuZb6SrEryuSQHkxxI8tZh9zQXSZ6bZH+Sr3bX8e5h9zRfSZYk+UqSe4bdy3wkOZLka0keSDI+7H7mKsmlSe5M8lD35+XlAz3+Yp1z7x5x8J/0POIAeP1ifMRBklcAjwMfqqoXD7uf+UiyHFheVV9OcglwP7Bxsf13SRLg4qp6PMmzgS8Ab62qLw65tTlL8qfAKPDCqnrNsPuZqyRHgNGqWtRfYkoyBvxrVd3efarw+VX1/UEdfzHfuf/fIw6q6qfAk484WHSq6vPAd4fdxyBU1fGq+nK3/kPgILBiuF2dv5ryeLf57O7X4rwTApKsBG4Cbh92L4IkLwReAdwBUFU/HWSww+IO9xXA0Z7tCRZhiLQsyWrgeuC+IbcyJ900xgPASWBvVS3K6+i8F3gH8LMh9zEIBXw6yf3dY0wWoxcBk8AHuqmy25NcPMgTLOZwn/URBxqeJC8APga8rap+MOx+5qKqTlfVdUx9w3ptkkU5ZZbkNcDJqrp/2L0MyA1V9VLg1cDWblpzsVkKvBR4X1VdD/wIGOj7hos53H3EwQWqm6P+GPCRqvqnYfczX91fl+8F1g+3kzm7AXhdN1e9C3hlkg8Pt6W5q6pj3fIkcBdTU7SLzQQw0fO3wTuZCvuBWczh7iMOLkDdG5F3AAer6j3D7meukowkubRbfx7wKuChoTY1R1W1vapWVtVqpv6cfLaq3jDktuYkycXdG/V00xi/Byy6T5lV1beAo0mu7krrGPAj0RfqqZALbgiPOFgwST4K/DZwRZIJ4F1Vdcdwu5qzG4A3Al/r5qsB3llVnxheS3OyHBjrPpX1LGB3VS3qjxA2Yhlw19Q9BEuBv6+qTw63pTl7C/CR7ub0EeBNgzz4ov0opCRpZot5WkaSNAPDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXofwFVYQ14i5lRwAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# we want to look at the numeric and categorical values seperately\n",
    "df_num = training[['Age', 'SibSp', 'Parch', 'Fare']] # we want to understand these with histograms\n",
    "df_cat = training[['Survived', 'Pclass', 'Sex', 'Ticket', 'Cabin', 'Embarked']] # we want to understand these with value counts\n",
    "\n",
    "# histograms for the numeric variables \n",
    "for i in df_num.columns:\n",
    "    plt.hist(df_num[i])\n",
    "    plt.title(i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c032de",
   "metadata": {},
   "source": [
    "We see that age follows a fairly normal distribution, but the other three do not. We might want to normalize the fare variable because we see such a spike at a low price. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7a6e9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Age     SibSp     Parch      Fare\n",
      "Age    1.000000 -0.308247 -0.189119  0.096067\n",
      "SibSp -0.308247  1.000000  0.414838  0.159651\n",
      "Parch -0.189119  0.414838  1.000000  0.216225\n",
      "Fare   0.096067  0.159651  0.216225  1.000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(df_num.corr())\n",
    "sns.heatmap(df_num.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcfebb4",
   "metadata": {},
   "source": [
    "From the heatmap we can see that SibSp and Parch are correlated, but something like Age and SibSp are negatively correlated. This is important to look at especially if we are doing regression because we don't want multicollinearity in our model. (Though this project is a classification problem) Next we want to compare the survival rate across Age, SibSp, Parch and Fare - i.e. the numeric variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3efdd8d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Parch</th>\n",
       "      <th>SibSp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30.626179</td>\n",
       "      <td>22.117887</td>\n",
       "      <td>0.329690</td>\n",
       "      <td>0.553734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28.343690</td>\n",
       "      <td>48.395408</td>\n",
       "      <td>0.464912</td>\n",
       "      <td>0.473684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Age       Fare     Parch     SibSp\n",
       "Survived                                          \n",
       "0         30.626179  22.117887  0.329690  0.553734\n",
       "1         28.343690  48.395408  0.464912  0.473684"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(training, index = \"Survived\", values = [\"Age\", \"SibSp\", \"Parch\", \"Fare\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add6a257",
   "metadata": {},
   "source": [
    "We see that the average age of those who survived and didn't the average fare paid for those who survived and didn't etc. Notes down the significant differences i.e. it seems that the average fare for those that survived is significantly higher than the average fare price for those who didn't We also see that the average number of parents/children for those that survived is larger, so perhaps families that had children were given higher priority? Next we want to look at the categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c271efa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in df_cat.columns:\n",
    "    sns.barplot(df_cat[i].value_counts().index,df_cat[i].value_counts()).set_title(i)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94acaad",
   "metadata": {},
   "source": [
    "1st Plot: survival rate i.e. how many people surived and how many didn't\n",
    "2nd Plot: how many people were in each class (1 is 1st class, 3 is 3rd class)\n",
    "3rd: how many males and females\n",
    "4th: unintelligeble \n",
    "5th: unintelligible \n",
    "6th: how many people embarked from where\n",
    "Since 4 (ticket number) and 5 (cabin number) are unintelligeble, we want to think about doing some feature engineering on them. Next we want to compare the survival of each of these categorical variables (just like with the numerical ones) except the ones that are unintelligeble - we will work on them in the feature engineering section. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e5101fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass      1   2    3\n",
      "Survived              \n",
      "0          80  97  372\n",
      "1         136  87  119\n",
      "Sex       female  male\n",
      "Survived              \n",
      "0             81   468\n",
      "1            233   109\n",
      "Embarked   C   Q    S\n",
      "Survived             \n",
      "0         75  47  427\n",
      "1         93  30  217\n"
     ]
    }
   ],
   "source": [
    "print(pd.pivot_table(training, index = \"Survived\", columns = \"Pclass\", values = \"Ticket\", aggfunc = \"count\"))\n",
    "print(pd.pivot_table(training, index = \"Survived\", columns = \"Sex\", values = \"Ticket\", aggfunc = \"count\"))\n",
    "print(pd.pivot_table(training, index = \"Survived\", columns = \"Embarked\", values = \"Ticket\", aggfunc = \"count\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72afa26",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35ecb17",
   "metadata": {},
   "source": [
    "Consider simplifying tickets and cabins because there will just be too many columns if we include them into our model \n",
    "1. Cabin \n",
    "2. Tickets - do different ticket types impact survival rates \n",
    "3. Does a person's title relate to survival rates \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3c78dd",
   "metadata": {},
   "source": [
    "### Cabin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18255d74",
   "metadata": {},
   "source": [
    "We want to first look at simplifying cabins - we can consider  splitting cabins - we want to try andsimplify cabins into categories with less columns, so we will look at the letter of the cabin and the purchase of tickets across multiple cabins "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8fd23c9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    687\n",
       "1    180\n",
       "2     16\n",
       "3      6\n",
       "4      2\n",
       "Name: cabin_multiple, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Potential splits:\n",
    "# cabin letter cabin_adv\n",
    "# purchase of tickets across multiple cabins cabin_multiple\n",
    "# First we look at cabin_multiple \n",
    "# i.e. we are seeing if people had multiple cabins \n",
    "df_cat.Cabin\n",
    "training[\"cabin_multiple\"] = training.Cabin.apply(lambda x : 0 if pd.isna(x) else len(x.split(\" \"))) # split on spaces and also adding the cabin_multiple variable to our dataset\n",
    "training['cabin_multiple'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd20baa",
   "metadata": {},
   "source": [
    "We see that the vast majority of people did not have multiple cabins (0 = 687)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "991d4692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>cabin_multiple</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>481.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>206.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "cabin_multiple      0      1    2    3    4\n",
       "Survived                                   \n",
       "0               481.0   58.0  7.0  3.0  NaN\n",
       "1               206.0  122.0  9.0  3.0  2.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(training, index = \"Survived\", columns = \"cabin_multiple\", values = \"Ticket\", aggfunc = \"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5fe82cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n    687\n",
      "C     59\n",
      "B     47\n",
      "D     33\n",
      "E     32\n",
      "A     15\n",
      "F     13\n",
      "G      4\n",
      "T      1\n",
      "Name: cabin_adv, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>cabin_adv</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>T</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>481.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>206.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "cabin_adv    A     B     C     D     E    F    G    T      n\n",
       "Survived                                                    \n",
       "0          8.0  12.0  24.0   8.0   8.0  5.0  2.0  1.0  481.0\n",
       "1          7.0  35.0  35.0  25.0  24.0  8.0  2.0  NaN  206.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# next we can look at the cabin letters\n",
    "# we look at this because we would expect that cabins with the same letters will be on the same floor and area\n",
    "# may make escape easier or harder \n",
    "training[\"cabin_adv\"] = training.Cabin.apply(lambda x: str(x)[0]) # adding the cabin_adv variable to our training set\n",
    "print(training.cabin_adv.value_counts())\n",
    "pd.pivot_table(training, index=\"Survived\", columns=\"cabin_adv\", values=\"Ticket\",aggfunc = \"count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a19cf1",
   "metadata": {},
   "source": [
    "We can see that generally, people who had cabins tended to survive more than people without, so it is likely we can use this cabin_adv variable in our model. (i.e. we can use the letter of the cabin as a categorical variable in our model). It also takes it from us having 50 to 100 unique cabins to having just a few. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cbc18bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next we want to understand ticket values better \n",
    "# numeric vs non-numeric \n",
    "# each ticket number was unique, but some had letters and some didn't \n",
    "training['numeric_ticket'] = training.Ticket.apply(lambda x: 1 if x.isnumeric() else 0)\n",
    "training['ticket_letters'] = training.Ticket.apply(lambda x: ''.join(x.split(' ')[:-1]).replace('.','').replace('/','').lower() if len(x.split(' ')[:-1]) > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c004d969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    661\n",
       "0    230\n",
       "Name: numeric_ticket, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training['numeric_ticket'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f5d1425b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            665\n",
       "pc            60\n",
       "ca            41\n",
       "a5            21\n",
       "stono2        18\n",
       "sotonoq       15\n",
       "scparis       11\n",
       "wc            10\n",
       "a4             7\n",
       "soc            6\n",
       "fcc            5\n",
       "c              5\n",
       "sopp           3\n",
       "pp             3\n",
       "wep            3\n",
       "ppp            2\n",
       "scah           2\n",
       "sotono2        2\n",
       "swpp           2\n",
       "fc             1\n",
       "scahbasle      1\n",
       "as             1\n",
       "sp             1\n",
       "sc             1\n",
       "scow           1\n",
       "fa             1\n",
       "sop            1\n",
       "sca4           1\n",
       "casoton        1\n",
       "Name: ticket_letters, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let us view all rows in the dataframe through scrolling (for convenience)\n",
    "pd.set_option(\"max_rows\", None)\n",
    "training['ticket_letters'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce814a3",
   "metadata": {},
   "source": [
    "Probably won't include the specific ticket letters as something that is significant in the analysis - might be worth it to do if we want to do a deeper analysis, but there aren't enough unique ones to make it seem that important. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "82681edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>numeric_ticket</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>142</td>\n",
       "      <td>407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "numeric_ticket    0    1\n",
       "Survived                \n",
       "0               142  407\n",
       "1                88  254"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# difference in numeric vs non-numeric tickets in survival rate \n",
    "pd.pivot_table(training,index='Survived', columns='numeric_ticket',values='Ticket', aggfunc='count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27be269b",
   "metadata": {},
   "source": [
    "We want to see if the difference in numeric vs non-numeric tickets had any impact on the survival rate. It looks like the ratios are fairly similar (142/407 and 88/254) - no significant difference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c77fcd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ticket_letters</th>\n",
       "      <th>0</th>\n",
       "      <th>a4</th>\n",
       "      <th>a5</th>\n",
       "      <th>as</th>\n",
       "      <th>c</th>\n",
       "      <th>ca</th>\n",
       "      <th>casoton</th>\n",
       "      <th>fa</th>\n",
       "      <th>fc</th>\n",
       "      <th>fcc</th>\n",
       "      <th>...</th>\n",
       "      <th>soc</th>\n",
       "      <th>sop</th>\n",
       "      <th>sopp</th>\n",
       "      <th>sotono2</th>\n",
       "      <th>sotonoq</th>\n",
       "      <th>sp</th>\n",
       "      <th>stono2</th>\n",
       "      <th>swpp</th>\n",
       "      <th>wc</th>\n",
       "      <th>wep</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>410.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>255.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows  29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "ticket_letters      0   a4    a5   as    c    ca  casoton   fa   fc  fcc  ...  \\\n",
       "Survived                                                                  ...   \n",
       "0               410.0  7.0  19.0  1.0  3.0  27.0      1.0  1.0  1.0  1.0  ...   \n",
       "1               255.0  NaN   2.0  NaN  2.0  14.0      NaN  NaN  NaN  4.0  ...   \n",
       "\n",
       "ticket_letters  soc  sop  sopp  sotono2  sotonoq   sp  stono2  swpp   wc  wep  \n",
       "Survived                                                                       \n",
       "0               5.0  1.0   3.0      2.0     13.0  1.0    10.0   NaN  9.0  2.0  \n",
       "1               1.0  NaN   NaN      NaN      2.0  NaN     8.0   2.0  1.0  1.0  \n",
       "\n",
       "[2 rows x 29 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we take a look at the survival rate with different ticket types (letters) \n",
    "pd.pivot_table(training, index='Survived', columns='ticket_letters',values='Ticket',aggfunc='count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca32f14f",
   "metadata": {},
   "source": [
    "Nothing too relevant with the ticket letters here either. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d83d3697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering on a person's title (mr, ms, misses etc.)\n",
    "training.Name.head(50)\n",
    "training['name_title'] = training.Name.apply(lambda x: x.split(',')[1].split('.')[0].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0795944d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mr              517\n",
       "Miss            182\n",
       "Mrs             125\n",
       "Master           40\n",
       "Dr                7\n",
       "Rev               6\n",
       "Mlle              2\n",
       "Major             2\n",
       "Col               2\n",
       "the Countess      1\n",
       "Capt              1\n",
       "Ms                1\n",
       "Sir               1\n",
       "Lady              1\n",
       "Mme               1\n",
       "Don               1\n",
       "Jonkheer          1\n",
       "Name: name_title, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training['name_title'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9a6014",
   "metadata": {},
   "source": [
    "We look at these because we want to see whether or not some of these have any effects on the survival rate - is someone who is royalty more likely to survive? Gives us more insight into the people rather than just have a male and female category. We see here that there aren't too many different surnames. To improve this, it might be better if we tried to group some of the people togeter, eg. Doctor, Rev, Mlle can be grouped together as working class people, or something along those lines. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b019cfc1",
   "metadata": {},
   "source": [
    "## Data Preprocessing for Model \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82f4a95",
   "metadata": {},
   "source": [
    "After exploring the data, we will move on to data preprocessing.  \n",
    "  \n",
    "1. Drop null values from Embarked (only 2)  \n",
    "2. Include only relevant variables   \n",
    "variables: Pclass, Sex, Age, Sibsp, Parch, Fare, Embarked, cabin_adv, cabin_multiple, numeric_ticket, name_title \n",
    "  \n",
    "3. Do categorical transforms on all the data. Usually we would use a transformer, but with this approach we can ensure our training and test data have the same columns. We also may be able to infer something about the shape of the test data through this method. I will stress, this is generally not recommended outside of a competition - usually you will use one hot encoder.Here, we use pandas getdummies(). This means that when you have multiple categorical variables (eg. cabin has 7 different things), in order for the model to use that, for each of those individual cabins, you need one column and the column has a 0 if they weren't in that cabin and a 1 if they were in that cabin \n",
    "\n",
    "4. Impute data with mean for fare and age - also try using the median \n",
    "5. Normalized fare using logarithm to give more semblance of a normal distribution \n",
    "6. Scaled data 0-1 with standard scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "81d47779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(889,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create all categorical variables that we did above for both training and test sets - notice here that we are using all the data, so we ensure that the training and test sets both have the same column names \n",
    "all_data['cabin_multiple'] = all_data.Cabin.apply(lambda x: 0 if pd.isna(x) else len(x.split(' ')))\n",
    "all_data['cabin_adv'] = all_data.Cabin.apply(lambda x: str(x)[0])\n",
    "all_data['numeric_ticket'] = all_data.Ticket.apply(lambda x: 1 if x.isnumeric() else 0)\n",
    "all_data['ticket_letters'] = all_data.Ticket.apply(lambda x: ''.join(x.split(' ')[:-1]).replace('.','').replace('/', '').lower() if len(x.split(' ')[:-1]) > 0 else 0)\n",
    "all_data['name_title'] = all_data.Name.apply(lambda x: x.split(',')[1].split('.')[0].strip())\n",
    "\n",
    "# impute nulls for continuous data \n",
    "all_data.Age = all_data.Age.fillna(training.Age.mean())\n",
    "all_data.Fare = all_data.Fare.fillna(training.Fare.mean())\n",
    "# in theory we should have used the median for Fare because it is not normally distributed\n",
    "\n",
    "# drop null 'embarked' rows. Only two instances of this in training and 0 in test \n",
    "all_data.dropna(subset = ['Embarked'], inplace = True)\n",
    "\n",
    "# trying to normalize a couple variables \n",
    "# tried log norm of sibsp (normalize siblings variable) - didn't use this\n",
    "all_data['norm_sibsp'] = np.log(all_data.SibSp + 1)\n",
    "all_data['norm_sibsp'].hist() \n",
    "\n",
    "# log norm of fare - used this\n",
    "all_data['norm_fare'] = np.log(all_data.Fare + 1)\n",
    "all_data['norm_fare'].hist()\n",
    "\n",
    "# converted fare to category for pd.get_dummies()\n",
    "all_data.Pclass = all_data.Pclass.astype(str)\n",
    "\n",
    "# created dummy variables from categories - can also use OneHotEncoder\n",
    "all_dummies = pd.get_dummies(all_data[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'norm_fare', 'Embarked', 'cabin_adv', 'cabin_multiple', 'numeric_ticket', 'name_title', 'train_test']])\n",
    "\n",
    "# Split to train test set again \n",
    "X_train = all_dummies[all_dummies.train_test == 1].drop(['train_test'], axis = 1)\n",
    "X_test = all_dummies[all_dummies.train_test == 0].drop(['train_test'], axis = 1)\n",
    "\n",
    "y_train = all_data[all_data.train_test == 1].Survived\n",
    "y_train.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05599c34",
   "metadata": {},
   "source": [
    "After normalizing the Fare, we get a shape that is closer to Normal distribution here. Note this is the historgram of hte Fare variable after normalizing (the orange bars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "af2366a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "scale = StandardScaler()\n",
    "all_dummies_scaled = all_dummies.copy()\n",
    "all_dummies_scaled[['Age', 'SibSp', 'Parch', 'norm_fare']] = scale.fit_transform(all_dummies_scaled[['Age', 'SibSp', 'Parch', 'norm_fare']])\n",
    "all_dummies_scaled \n",
    "\n",
    "X_train_scaled = all_dummies_scaled[all_dummies_scaled.train_test == 1].drop(['train_test'], axis=1)\n",
    "X_test_scaled = all_dummies_scaled[all_dummies_scaled.train_test == 0].drop(['train_test'], axis=1)\n",
    "\n",
    "y_train = all_data[all_data.train_test==1].Survived"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1b09be",
   "metadata": {},
   "source": [
    "## Model Building\n",
    "\n",
    "Here we want to try a bunch of different models and experiment with how they do. We want to see how various models perform with some default parameters. Tried the following models with 5 fold cross validation to get a baseline. With a validation set basleine, we can see how much tuning improves each of these models. But note that just because a model has a high baseline on a validation set doesn't mean that it will do well on the eventual test set. &nbsp;\n",
    "\n",
    "The models tried are: \n",
    "- Naive Bayes \n",
    "- Logistic Regression \n",
    "- Decision Tree \n",
    "- KNN \n",
    "- Random Forest \n",
    "- Support Vector Classifier \n",
    "- Xtreme Gradient Boosting \n",
    "- Soft Voting Classifier \n",
    "\n",
    "&nbsp;\n",
    "We use cross validation - this takes some of the samples from our training set and splits them off, and it randomly samples from our training data, we run a model on some of that training data, and then it predicts. This way we validate the model on data that is held out and that should give us a better estimation of how it will perform in the real world. First we will train on the above models with no parameter tuning just to see how they perform. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "797126c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fefc9199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.66853933 0.70224719 0.75842697 0.74719101 0.73446328]\n",
      "0.7221735542436362\n"
     ]
    }
   ],
   "source": [
    "# Usually we can use Naive Bayes as a baseline for classification- simple model and we always expect other models to do better.\n",
    "# The general way is to just import the models from sklearn, create an instance of it and then fit it to the data. \n",
    "gnb = GaussianNB()\n",
    "cv = cross_val_score(gnb, X_train_scaled, y_train, cv=5)\n",
    "print(cv)\n",
    "print(cv.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "956937af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.82022472 0.80898876 0.80337079 0.82022472 0.85310734]\n",
      "0.8211832666793626\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter = 2000)\n",
    "cv = cross_val_score(lr, X_train, y_train, cv = 5)\n",
    "print(cv)\n",
    "print(cv.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c8bce535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.82022472 0.80898876 0.80337079 0.82022472 0.85310734]\n",
      "0.8211832666793626\n"
     ]
    }
   ],
   "source": [
    "# logistic regression on the scaled data \n",
    "lr = LogisticRegression(max_iter = 2000)\n",
    "cv = cross_val_score(lr, X_train_scaled, y_train, cv = 5)\n",
    "print(cv)\n",
    "print(cv.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3addc890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.74719101 0.74157303 0.80898876 0.75842697 0.82485876]\n",
      "0.776207706468609\n"
     ]
    }
   ],
   "source": [
    "dt = tree.DecisionTreeClassifier(random_state = 1)\n",
    "cv = cross_val_score(dt, X_train, y_train, cv=5)\n",
    "print(cv)\n",
    "print(cv.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9c73b8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.74719101 0.74157303 0.80898876 0.75280899 0.81920904]\n",
      "0.7739541674601662\n"
     ]
    }
   ],
   "source": [
    "# Decision tree on the scaled data \n",
    "dt = tree.DecisionTreeClassifier(random_state = 1)\n",
    "cv = cross_val_score(dt, X_train_scaled, y_train, cv=5)\n",
    "print(cv)\n",
    "print(cv.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "95d66fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.76966292 0.80898876 0.80337079 0.81460674 0.83615819]\n",
      "0.8065574811147084\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "cv = cross_val_score(knn, X_train, y_train, cv=5)\n",
    "print(cv)\n",
    "print(cv.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fdcdfd5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.79775281 0.79213483 0.83146067 0.80337079 0.85310734]\n",
      "0.8155652891512728\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "cv = cross_val_score(knn, X_train_scaled, y_train, cv=5)\n",
    "print(cv)\n",
    "print(cv.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2715dac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.82022472 0.78651685 0.85393258 0.73033708 0.84180791]\n",
      "0.8065638291119152\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state = 1)\n",
    "cv = cross_val_score(rf, X_train, y_train, cv=5)\n",
    "print(cv)\n",
    "print(cv.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1608fd24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.81460674 0.78651685 0.85393258 0.73033708 0.84180791]\n",
      "0.8054402336062972\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state = 1)\n",
    "cv = cross_val_score(rf, X_train_scaled, y_train, cv=5)\n",
    "print(cv)\n",
    "print(cv.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "66863866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.84831461 0.82022472 0.8258427  0.80337079 0.86440678]\n",
      "0.8324319177299563\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(probability = True)\n",
    "cv = cross_val_score(svc, X_train_scaled, y_train, cv=5)\n",
    "print(cv)\n",
    "print(cv.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0d12a77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:30:10] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:30:10] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:30:10] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:30:10] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:30:10] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0.8258427  0.80898876 0.84831461 0.78651685 0.81920904]\n",
      "0.8177743921792675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier(random_state = 1)\n",
    "cv = cross_val_score(xgb, X_train_scaled, y_train, cv=5)\n",
    "print(cv)\n",
    "print(cv.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a14a8eb",
   "metadata": {},
   "source": [
    "Voting classifier - takes all the inputs and averages the results. For a \"hard\" voting classifier, each classifier gets one vote, a \"yes\" or \"no\" and the result is just a popular vote. For this, you generally want odd numbers. &nbsp;\n",
    "\n",
    "A \"soft\" voting classifier averages the confidence of each of the models. If the average confidence is > 50% (that is it is a 1), it will be counted as such. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "adbd19df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier \n",
    "voting_clf = VotingClassifier(estimators = [('lr', lr), ('knn', knn), ('rf', rf), ('gnb', gnb), ('svc', svc), ('xgb', xgb)], voting = 'soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "11697679",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:36:35] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:36:35] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:36:36] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:36:36] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:36:36] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0.83146067 0.81460674 0.83146067 0.80337079 0.85875706]\n",
      "0.8279311877102774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "cv = cross_val_score(voting_clf, X_train_scaled, y_train, cv=5)\n",
    "print(cv)\n",
    "print(cv.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c1f01542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:34:38] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "voting_clf.fit(X_train_scaled, y_train)\n",
    "y_hat_base_vc = voting_clf.predict(X_test_scaled)\n",
    "basic_submission = {'PassengerId': test.PassengerId, 'Survived': y_hat_base_vc}\n",
    "base_submission = pd.DataFrame(data = basic_submission)\n",
    "base_submission.to_csv('base_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b49ba0",
   "metadata": {},
   "source": [
    "## Model Tuning\n",
    "\n",
    "After getting the baselines, lets see if we can improve on the individual model results. We will try using grid search to tune the models. We can also use Randomized search for the Random Forest and XG Boosted model to simplify testing time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8780332f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "339cb270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple performance reporting function \n",
    "def clf_performance(classifier, model_name):\n",
    "    print(model_name)\n",
    "    print('Best Score: ' + str(classifier.best_score_))\n",
    "    print('Best Parameters: ' + str(classifier.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bb21ea96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search allows us to put in a bunch of parameters and try them all. It spits out a bunch of parameters that return the\n",
    "# best results. \n",
    "lr = LogisticRegression()\n",
    "param_grid = {'max iter' : [2000], \n",
    "              'penalty' : ['l1', 'l2'], \n",
    "              'C' : np.logspace(-4,4,20), \n",
    "              'solver': ['liblinear']}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0459e8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter max iter for estimator LogisticRegression(C=0.0001). Check the list of available parameters with `estimator.get_params().keys()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 436, in _process_worker\n    r = call_item()\n  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 288, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 595, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n    return [func(*args, **kwargs)\n  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n    return self.function(*args, **kwargs)\n  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 586, in _fit_and_score\n    estimator = estimator.set_params(**cloned_parameters)\n  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 230, in set_params\n    raise ValueError('Invalid parameter %s for estimator %s. '\nValueError: Invalid parameter max iter for estimator LogisticRegression(C=0.0001). Check the list of available parameters with `estimator.get_params().keys()`.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25672/863609752.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mclf_lr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mbest_clf_lr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf_lr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mclf_performance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_clf_lr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Logistic Regression'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    839\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 841\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1294\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1295\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1296\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1054\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1055\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1056\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1057\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    933\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 935\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    936\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    443\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 445\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    446\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    388\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 390\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    391\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m                 \u001b[1;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid parameter max iter for estimator LogisticRegression(C=0.0001). Check the list of available parameters with `estimator.get_params().keys()`."
     ]
    }
   ],
   "source": [
    "clf_lr = GridSearchCV(lr, param_grid=param_grid, cv = 5, verbose = True, n_jobs = -1)\n",
    "best_clf_lr = clf_lr.fit(X_train_scaled, y_train)\n",
    "clf_performance(best_clf_lr, 'Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5da26965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "KNN\n",
      "Best Score: 0.8301720307243065\n",
      "Best Parameters: {'algorithm': 'auto', 'n_neighbors': 7, 'p': 2, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "param_grid = {'n_neighbors' : [3,5,7,9], \n",
    "              'weights' : ['uniform', 'distance'], \n",
    "              'algorithm' : ['auto', 'ball_tree', 'kd_tree'], \n",
    "              'p' : [1,2]}\n",
    "clf_knn = GridSearchCV(knn, param_grid=param_grid, cv=5, verbose=True, n_jobs= -1)\n",
    "best_clf_knn = clf_knn.fit(X_train_scaled, y_train)\n",
    "clf_performance(best_clf_knn, 'KNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2a2d2f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "SVC\n",
      "Best Score: 0.8324319177299563\n",
      "Best Parameters: {'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(probability = True)\n",
    "param_grid = tuned_parameters = [{'kernel' : ['rbf'], \n",
    "                                  'gamma' : [.1, .5, 1, 2, 5, 10], \n",
    "                                  'C': [.1, 1, 10, 100, 1000] }, \n",
    "                                 {'kernel' : ['linear'], \n",
    "                                  'C': [.1 , 1, 10, 100, 1000]}, \n",
    "                                 {'kernel': ['poly'], 'degree':[2,3,4,5], \n",
    "                                  'C':[.1,1,10,100,1000]}]\n",
    "clf_svc = GridSearchCV(svc, param_grid=param_grid, cv=5, verbose = True, n_jobs=-1)\n",
    "best_clf_svc = clf_svc.fit(X_train_scaled, y_train)\n",
    "clf_performance(best_clf_svc, 'SVC')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b992ee4a",
   "metadata": {},
   "source": [
    "For RandomForest (and also XGBoost later), there are technically an infinite number of parameters that we can try. It would take a very long time since hte total feature space is so large. Thus, we use a randomized search to narrow down the parameters of the model. We then take the best model from this and do a more granular search. A randomized search just means it doesn't try all of the params in the param_grid, it randomly samples from the options in the param_grid and then returns the best results from that. Then after getting the best results, we can tune it further and try to get something that might perform a little bit better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "50dbb3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Random Forest\n",
      "Best Score: 0.8335301212467467\n",
      "Best Parameters: {'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 20, 'bootstrap': False}\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state = 1)\n",
    "param_grid = {'n_estimators': [100,500,1000], \n",
    "              'bootstrap': [True,False], \n",
    "              'max_depth': [3,5,10,20,50,75,100,None], \n",
    "              'max_features': ['auto', 'sqrt'], \n",
    "              'min_samples_leaf': [1,2,4,10], \n",
    "              'min_samples_split': [2,5,10]}\n",
    "\n",
    "clf_rf_rnd = RandomizedSearchCV(rf, param_distributions = param_grid, n_iter = 100, cv = 5, verbose = True, n_jobs = -1)\n",
    "best_clf_rf_rnd = clf_rf_rnd.fit(X_train_scaled, y_train)\n",
    "clf_performance(best_clf_rf_rnd, 'Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ef394fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n",
      "Random Forest\n",
      "Best Score: 0.8358027042468101\n",
      "Best Parameters: {'bootstrap': True, 'criterion': 'gini', 'max_depth': 20, 'max_features': 10, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state = 1)\n",
    "param_grid = {'n_estimators': [400,450,500,550], \n",
    "              'criterion':['gini', 'entropy'], \n",
    "              'bootstrap': [True], 'max_depth': [15,20,25], \n",
    "              'max_features': ['auto', 'sqrt', 10], \n",
    "              'min_samples_leaf': [2,3], \n",
    "              'min_samples_split' : [2,3]}\n",
    "\n",
    "clf_rf = GridSearchCV(rf, param_grid = param_grid, cv=5, verbose = True, n_jobs = -1)\n",
    "best_clf_rf = clf_rf.fit(X_train_scaled, y_train)\n",
    "clf_performance(best_clf_rf, 'Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "709a1a17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# taking a quick look at feature importances:\n",
    "# i.e. which features have the greatest impact in predicting whether someone survives or not \n",
    "best_rf = best_clf_rf.best_estimator_.fit(X_train_scaled, y_train)\n",
    "feat_importances = pd.Series(best_rf.feature_importances_, index=X_train_scaled.columns)\n",
    "feat_importances.nlargest(20).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "90ebda21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4762800 candidates, totalling 23814000 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25672/1863304846.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# Grid Search\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mclf_xgb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxgb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mbest_clf_xgb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf_xgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[0mclf_performance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_clf_xgb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'XGB'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    839\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 841\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1294\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1295\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1296\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1054\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1055\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1056\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1057\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    933\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 935\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    936\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    438\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    310\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(random_state = 1)\n",
    "\n",
    "param_grid = {'n_estimators': [20,50,100,250,500,1000], \n",
    "              'colsample_bytree' : [0.2,0.5,0.7,0.8,1], \n",
    "              'max_depth': [2,5,10,15,20,25,None], \n",
    "              'reg_alpha': [0,0.5,1], \n",
    "              'reg_lambda': [1, 1.5,2], \n",
    "              'subsample': [0.5,0.6,0.7,0.8,0.9], \n",
    "              'learning_rate':[.01,0.1,0.2,0.3,0.5,0.7,0.9],\n",
    "              'gamma':[0,.01,0.1,1,10,100], \n",
    "              'min_child_weight' : [0,.01,0.1,1,10,100], \n",
    "              'sampling_method' : ['uniform', 'gradient_based']}\n",
    "\n",
    "# Grid Search\n",
    "# clf_xgb = GridSearchCV(xgb, param_grid = param_grid, cv = 5, verbose = True, n_jobs = -1)\n",
    "# best_clf_xgb = clf_xgb.fit(X_train_scaled, y_train)\n",
    "# clf_performance(best_clf_xgb, 'XGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c5cae0bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1000 candidates, totalling 5000 fits\n",
      "[12:30:22] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGB\n",
      "Best Score: 0.8504030978226369\n",
      "Best Parameters: {'subsample': 0.8, 'sampling_method': 'uniform', 'reg_lambda': 2, 'reg_alpha': 0, 'n_estimators': 250, 'min_child_weight': 0.1, 'max_depth': 2, 'learning_rate': 0.3, 'gamma': 0, 'colsample_bytree': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:922: UserWarning: One or more of the test scores are non-finite: [0.78739923 0.84029709        nan 0.61754586        nan        nan\n",
      "        nan        nan        nan 0.84138259 0.83354917        nan\n",
      " 0.61754586 0.61754586        nan        nan 0.84253158 0.81665714\n",
      "        nan        nan        nan        nan        nan 0.83014029\n",
      " 0.81891068 0.61754586        nan        nan        nan 0.82677585\n",
      " 0.61754586        nan        nan        nan 0.83131467        nan\n",
      "        nan 0.74919698        nan        nan 0.61754586 0.79753698\n",
      " 0.78627563 0.78627563 0.81439726 0.8380372  0.8155399         nan\n",
      " 0.65144417        nan        nan        nan 0.83466006 0.78627563\n",
      "        nan 0.61754586        nan        nan 0.81778709        nan\n",
      " 0.61754586        nan        nan 0.83463467        nan        nan\n",
      " 0.82004063 0.81328636        nan 0.79867962 0.83467276 0.8053958\n",
      "        nan        nan 0.79979052 0.8256586  0.61754586 0.81892338\n",
      " 0.83130197        nan 0.81439091 0.61754586        nan 0.61754586\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.61754586 0.81779978 0.61754586        nan        nan        nan\n",
      "        nan 0.80203771        nan        nan 0.61754586        nan\n",
      " 0.61754586 0.79978417 0.81553355 0.83579636        nan        nan\n",
      " 0.81779978        nan        nan 0.83353647 0.8166508         nan\n",
      " 0.81328636        nan        nan 0.61754586 0.8369136  0.80764934\n",
      " 0.80314226 0.80878563 0.82115787 0.82902939 0.61754586        nan\n",
      " 0.78178125 0.82452231 0.79078271 0.82004063 0.83353647        nan\n",
      "        nan 0.83127023 0.61754586        nan        nan        nan\n",
      "        nan 0.80537675        nan        nan        nan 0.81665714\n",
      " 0.83241922 0.80425951        nan 0.8369263  0.82115787 0.80316765\n",
      "        nan 0.84478512 0.80765568        nan 0.8155399  0.8009522\n",
      "        nan 0.78627563 0.83464737 0.82902939 0.78627563        nan\n",
      " 0.81326731        nan 0.78627563        nan        nan        nan\n",
      " 0.83241922        nan        nan 0.61754586 0.81554625 0.80652574\n",
      "        nan 0.61754586        nan 0.61754586 0.82677585        nan\n",
      "        nan        nan        nan        nan        nan 0.8166254\n",
      "        nan        nan        nan        nan 0.80880467        nan\n",
      "        nan 0.83127658 0.81217546        nan        nan 0.81666984\n",
      "        nan        nan 0.82115787        nan 0.83465372        nan\n",
      "        nan 0.78627563        nan        nan        nan        nan\n",
      " 0.81439726 0.78627563 0.80768742        nan 0.83017203 0.79753698\n",
      " 0.80880467 0.61754586 0.81442265        nan 0.83129563        nan\n",
      " 0.80653844 0.82118327        nan        nan 0.82567765 0.82566495\n",
      "        nan 0.61754586 0.79638799 0.61754586        nan        nan\n",
      " 0.83356186 0.84364883        nan 0.83803085        nan 0.81888529\n",
      "        nan        nan        nan        nan 0.83240653 0.81553355\n",
      "        nan 0.61754586 0.83688821 0.83466006 0.83019107        nan\n",
      "        nan        nan 0.82904209        nan        nan 0.78629467\n",
      " 0.80989653 0.83354282 0.81215007        nan 0.83240018 0.81779978\n",
      "        nan 0.61754586        nan        nan 0.8256586  0.80651939\n",
      " 0.83014664 0.82339872 0.61754586 0.78627563        nan 0.78627563\n",
      "        nan        nan        nan 0.71529867 0.8267822  0.61754586\n",
      " 0.814429          nan        nan 0.81103917        nan        nan\n",
      " 0.83688186 0.81329271        nan        nan        nan 0.8380499\n",
      "        nan 0.83017203        nan        nan 0.84027169 0.83239383\n",
      "        nan        nan        nan 0.82676316        nan        nan\n",
      "        nan 0.79753063 0.81556529 0.78627563        nan        nan\n",
      " 0.80766203        nan 0.79526439 0.81329271        nan 0.82116422\n",
      "        nan 0.82793119 0.82118327 0.78627563        nan 0.61754586\n",
      "        nan 0.83126389        nan 0.78178125        nan 0.61754586\n",
      "        nan 0.79643243        nan 0.77503967        nan        nan\n",
      " 0.80426585        nan 0.84253158 0.79864788 0.82680759        nan\n",
      "        nan 0.8267695         nan 0.79977782 0.83465372        nan\n",
      " 0.74919698        nan 0.8155399  0.82453501 0.84026535        nan\n",
      "        nan 0.83017838        nan        nan        nan        nan\n",
      " 0.82791214 0.82678855        nan        nan 0.81327366 0.78178125\n",
      " 0.83467911 0.83353012        nan 0.8256713         nan        nan\n",
      "        nan 0.80202501        nan        nan 0.81890434        nan\n",
      " 0.84253793        nan 0.83579636 0.61754586 0.78627563        nan\n",
      "        nan 0.61754586 0.8267822  0.80766838 0.84364883 0.61754586\n",
      " 0.8155399         nan        nan        nan 0.77841046        nan\n",
      " 0.81102647        nan        nan 0.77841046 0.79749889 0.61754586\n",
      " 0.83130197 0.61754586        nan        nan 0.81891703        nan\n",
      " 0.61754586 0.81890434        nan        nan        nan        nan\n",
      " 0.84137625        nan        nan        nan        nan 0.82680124\n",
      "        nan 0.83239383 0.82341776        nan        nan        nan\n",
      " 0.80313591 0.83688821 0.83130832 0.83693265        nan 0.81889799\n",
      "        nan        nan 0.79527074        nan 0.81891703 0.81328001\n",
      " 0.83130197        nan        nan        nan        nan        nan\n",
      "        nan 0.78627563        nan 0.81666984        nan        nan\n",
      " 0.83127658        nan        nan 0.61754586        nan 0.82567765\n",
      "        nan        nan 0.61754586 0.81102647 0.80879198        nan\n",
      " 0.61754586 0.83129563 0.61754586 0.61754586 0.81100743 0.81780613\n",
      "        nan 0.65462452 0.81101378 0.82791849        nan        nan\n",
      "        nan        nan        nan 0.61754586 0.82678855 0.81892338\n",
      " 0.83238113 0.79077001        nan 0.82115153        nan 0.82454136\n",
      " 0.61754586 0.61754586 0.80657653 0.8369136         nan        nan\n",
      "        nan        nan 0.68159081 0.81555259 0.61754586        nan\n",
      " 0.78627563        nan 0.83237479 0.82118961        nan 0.78627563\n",
      "        nan        nan 0.77840411 0.83575827        nan        nan\n",
      " 0.80876658        nan 0.82793754 0.83915445        nan        nan\n",
      "        nan        nan        nan        nan        nan 0.83017203\n",
      "        nan 0.61754586 0.78627563        nan        nan 0.82113883\n",
      "        nan 0.78178125 0.83015933 0.78627563        nan 0.81665714\n",
      " 0.65144417 0.67822002        nan        nan 0.81324827        nan\n",
      "        nan 0.67841046 0.80877293        nan        nan 0.81556529\n",
      " 0.75237732        nan 0.78965276 0.82905478 0.82341141        nan\n",
      " 0.82229417 0.82341141        nan        nan 0.83579001 0.78627563\n",
      " 0.61754586        nan 0.61754586        nan 0.61754586        nan\n",
      " 0.81102012 0.81778709 0.83464737        nan 0.79413445 0.80992192\n",
      "        nan 0.61754586 0.82228147 0.7930172  0.82675681        nan\n",
      " 0.83240653        nan        nan 0.82454136        nan        nan\n",
      " 0.78178125 0.78178125        nan        nan 0.83017838 0.78627563\n",
      " 0.80764934        nan 0.80991557        nan 0.82450962        nan\n",
      " 0.81890434        nan        nan        nan 0.61754586        nan\n",
      "        nan 0.80876658 0.61754586 0.81664445 0.61754586        nan\n",
      "        nan 0.78627563        nan        nan 0.61754586        nan\n",
      " 0.81665714 0.82451597 0.82227512        nan        nan        nan\n",
      " 0.82343046 0.78627563 0.81440361        nan        nan 0.83801816\n",
      " 0.83238113 0.83579636 0.8267695  0.81216276 0.71211833 0.81439091\n",
      "        nan        nan 0.78627563 0.82004698        nan        nan\n",
      "        nan 0.77278614 0.61754586        nan 0.82230051        nan\n",
      "        nan        nan 0.84140164        nan        nan        nan\n",
      "        nan        nan        nan 0.83804355        nan        nan\n",
      " 0.81442265        nan        nan 0.81557164        nan        nan\n",
      " 0.61754586 0.8504031  0.61754586 0.82341776        nan 0.8267949\n",
      "        nan 0.82789945 0.81779344        nan        nan        nan\n",
      " 0.61754586        nan        nan 0.78627563        nan        nan\n",
      " 0.61754586        nan 0.78627563        nan 0.61754586        nan\n",
      "        nan 0.61754586 0.82117692 0.8155272         nan        nan\n",
      "        nan 0.8380372  0.61754586        nan 0.78627563 0.8267822\n",
      " 0.80992827 0.82001524        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.83575192        nan\n",
      "        nan 0.8369136         nan        nan        nan        nan\n",
      "        nan 0.81215007        nan 0.61754586        nan        nan\n",
      " 0.61754586 0.61754586 0.83130197 0.83691995 0.82115153        nan\n",
      " 0.82454771        nan 0.61754586        nan 0.83467911 0.82793119\n",
      " 0.82902304        nan        nan 0.61754586        nan        nan\n",
      "        nan 0.81438456 0.61754586 0.83014029 0.78627563        nan\n",
      " 0.79866692 0.83353647        nan 0.61754586 0.83354917 0.81890434\n",
      "        nan        nan        nan 0.61754586 0.61754586        nan\n",
      " 0.82230686        nan 0.79641338        nan        nan        nan\n",
      " 0.81329905        nan 0.82901035 0.61754586 0.83690726 0.78627563\n",
      "        nan        nan        nan 0.83691995 0.82005332        nan\n",
      "        nan 0.8279058  0.61754586 0.8256713         nan 0.8133181\n",
      "        nan        nan 0.83353647 0.78178125 0.61754586 0.83130832\n",
      "        nan 0.81553355 0.61754586        nan        nan        nan\n",
      "        nan 0.82903574 0.61754586        nan        nan 0.81782518\n",
      " 0.61754586        nan        nan        nan        nan        nan\n",
      " 0.83015933        nan        nan 0.79415984 0.83014029 0.83464737\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.78178125 0.82343046 0.8177363  0.61754586 0.82903574\n",
      "        nan 0.83015933        nan        nan 0.83240653 0.8042722\n",
      " 0.61754586        nan 0.82116422        nan 0.82788675 0.84474703\n",
      " 0.61754586        nan 0.80202501        nan        nan 0.81554625\n",
      "        nan        nan        nan 0.61754586        nan        nan\n",
      "        nan 0.8155399         nan 0.61754586        nan        nan\n",
      " 0.78627563 0.83799911        nan 0.83129563 0.78741192        nan\n",
      " 0.81215641        nan 0.83015933 0.77615692 0.80764934 0.83019107\n",
      " 0.83238113        nan 0.81329271 0.81101378        nan 0.83577731\n",
      " 0.79977782        nan        nan        nan        nan        nan\n",
      " 0.84029709 0.82562052 0.61754586 0.81664445 0.84141433 0.61754586\n",
      "        nan        nan        nan 0.82454136 0.82002158 0.81101378\n",
      " 0.83128293        nan 0.61754586 0.82904844 0.8245604  0.82342411\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.82004063 0.7930172         nan        nan        nan\n",
      " 0.83014029 0.83691995        nan 0.78627563 0.79640703 0.78739288\n",
      "        nan        nan 0.8380499         nan 0.61754586 0.81100743\n",
      "        nan 0.80655113        nan 0.78627563        nan 0.83242557\n",
      " 0.81329271        nan 0.64451216 0.61754586 0.80990288        nan\n",
      "        nan 0.8380499         nan 0.82676316        nan 0.83129563\n",
      " 0.81893608 0.82904844        nan        nan        nan 0.81889799\n",
      " 0.84027804        nan 0.83463467        nan        nan 0.81103917\n",
      "        nan 0.82231321        nan        nan        nan 0.81891703\n",
      "        nan        nan        nan 0.79641973        nan 0.8267695\n",
      "        nan 0.79864153        nan 0.78178125        nan        nan\n",
      "        nan 0.79641973 0.61754586        nan        nan 0.8177617\n",
      " 0.83690091 0.8267949  0.82454136        nan        nan 0.81102012\n",
      "        nan        nan        nan 0.78178125        nan 0.61754586\n",
      " 0.78627563        nan        nan 0.81440995 0.83466641        nan\n",
      "        nan        nan 0.82115787        nan 0.83014029 0.82455405\n",
      "        nan        nan 0.81328001 0.82339872]\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Random Forest \n",
    "clf_xgb_rnd = RandomizedSearchCV(xgb, param_distributions = param_grid, n_iter=1000, cv=5, verbose=True, n_jobs = -1)\n",
    "best_clf_xgb_rnd = clf_xgb_rnd.fit(X_train_scaled, y_train)\n",
    "clf_performance(best_clf_xgb_rnd, 'XGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "132cd638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:13:29] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGB\n",
      "Best Score: 0.8526502888338727\n",
      "Best Parameters: {'colsample_bytree': 0.85, 'gamma': 1, 'learning_rate': 0.5, 'max_depth': None, 'min_child_weight': 0.01, 'n_estimators': 500, 'reg_alpha': 1, 'reg_lambda': 5, 'sampling_method': 'uniform', 'subsample': 0.65}\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(random_state = 1)\n",
    "\n",
    "param_grid = {'n_estimators' : [450,500,550], \n",
    "              'colsample_bytree' : [0.75,0.8,0.85], \n",
    "              'max_depth': [None], \n",
    "              'reg_alpha': [1], \n",
    "              'reg_lambda' : [2,5,10], \n",
    "              'subsample' : [0.55,0.6,0.65], \n",
    "              'learning_rate': [0.5], \n",
    "              'gamma':[0.5, 1,2], \n",
    "              'min_child_weight': [0.01], \n",
    "              'sampling_method': ['uniform']}\n",
    "\n",
    "clf_xgb = GridSearchCV(xgb, param_grid = param_grid, cv = 5, verbose = True, n_jobs = -1)\n",
    "best_clf_xgb = clf_xgb.fit(X_train_scaled, y_train)\n",
    "clf_performance(best_clf_xgb, 'XGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1ce100dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_xgb = best_clf_xgb.best_estimator_.predict(X_test_scaled)\n",
    "xgb_submission = {'PassengerId' : test.PassengerId, 'Survived' : y_hat_xgb}\n",
    "submission_xgb = pd.DataFrame(data=xgb_submission)\n",
    "submission_xgb.to_csv('xgb_submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2bd6ee",
   "metadata": {},
   "source": [
    "## Model additional ensemble approaches \n",
    "\n",
    "1. Experimented with a hard voting classifier of three estimators (KNN, SVM, RF)\n",
    "2. Experimented with a soft voting classifier of three estimators (KNN, SVM, RF)\n",
    "3. Experimented with a soft voting on all estimators performing better than 80% except XGB (KNN, RF, LR, SVC)\n",
    "4. Experimented with soft voting on all estimators including XGB (KNN, SVM, RF, LR, XGB) &nbsp;\n",
    "\n",
    "Here we are just taking all the best estimators and making a bunch of voting classifiers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "954d30d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_lr = best_clf_lr.best_estimator_ \n",
    "best_knn = best_clf_knn.best_estimator_\n",
    "best_svc = best_clf_svc.best_estimator_\n",
    "best_rf = best_clf_rf.best_estimator_\n",
    "best_xgb = best_clf_xgb.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1f891ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf_hard = VotingClassifier(estimators = [('knn', best_knn), ('rf', best_rf), ('svc', best_svc)], voting = 'hard')\n",
    "voting_clf_soft = VotingClassifier(estimators = [('knn', best_knn), ('rf', best_rf), ('svc', best_svc)], voting = 'soft')\n",
    "voting_clf_xgb = VotingClassifier(estimators = [('knn', best_knn), ('rf', best_rf), ('svc', best_svc), ('xgb', best_xgb)], voting = 'soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "511cb409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voting_clf_hard : [0.79213483 0.81460674 0.8258427  0.80898876 0.83615819]\n",
      "voting_clf_hard mean : 0.8155462451596522\n"
     ]
    }
   ],
   "source": [
    "print('voting_clf_hard :', cross_val_score(voting_clf_hard, X_train, y_train, cv=5))\n",
    "print('voting_clf_hard mean :', cross_val_score(voting_clf_hard, X_train, y_train, cv=5).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1f912010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voting_clf_soft : [0.78089888 0.83146067 0.82022472 0.81460674 0.86440678]\n",
      "voting_clf_soft mean : 0.8234431536850124\n"
     ]
    }
   ],
   "source": [
    "print('voting_clf_soft :', cross_val_score(voting_clf_soft, X_train, y_train, cv=5))\n",
    "print('voting_clf_soft mean :', cross_val_score(voting_clf_soft, X_train, y_train, cv=5).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bb0c47f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:48:46] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:48:47] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:48:48] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:48:49] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:48:50] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "voting_clf_xgb : [0.83707865 0.8258427  0.84269663 0.82022472 0.85310734]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:48:51] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:48:52] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:48:53] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:48:54] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:48:55] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "voting_clf_xgb mean : 0.8346600647495717\n"
     ]
    }
   ],
   "source": [
    "print('voting_clf_xgb :', cross_val_score(voting_clf_xgb, X_train, y_train, cv=5))\n",
    "print('voting_clf_xgb mean :', cross_val_score(voting_clf_xgb, X_train, y_train, cv=5).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a96a995",
   "metadata": {},
   "source": [
    "We want to see whether the weights of the models have any impact on the output here. Do a grid search and experiment with different votes in the soft voting classifier. So that means we add additional weightings to one or two of the models so that it counts for more in the analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3427270b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "VC Weights\n",
      "Best Score: 0.8324446137243701\n",
      "Best Parameters: {'weights': [1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "params = {'weights': [[1,1,1], [1,2,1], [1,1,2], [2,1,1], [2,2,1], [1,2,2], [2,1,2]]}\n",
    "\n",
    "vote_weight = GridSearchCV(voting_clf_soft, param_grid=params, cv = 5, verbose=True, n_jobs= -1)\n",
    "best_clf_weight = vote_weight.fit(X_train_scaled, y_train)\n",
    "clf_performance(best_clf_weight, 'VC Weights')\n",
    "voting_clf_sub = best_clf_weight.best_estimator_.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a18172",
   "metadata": {},
   "source": [
    "Making predictions. We go through and fit all the data. For each of the classifiers we made we need to fit it to the data, and then after we fit it we can predict the results we got. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9d70968e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:02:11] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "voting_clf_hard.fit(X_train_scaled, y_train)\n",
    "voting_clf_soft.fit(X_train_scaled, y_train)\n",
    "voting_clf_xgb.fit(X_train_scaled, y_train)\n",
    "\n",
    "best_rf.fit(X_train_scaled, y_train)\n",
    "y_hat_vc_hard = voting_clf_hard.predict(X_test_scaled)\n",
    "y_hat_rf = best_rf.predict(X_test_scaled)\n",
    "y_hat_vc_soft = voting_clf_soft.predict(X_test_scaled)\n",
    "y_hat_vc_xgb = voting_clf_xgb.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5cab0a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the outputs to a data frame\n",
    "final_data_1 = {'PassengerId': test.PassengerId, 'Survived': y_hat_rf}\n",
    "submission_1 = pd.DataFrame(data=final_data_1)\n",
    "\n",
    "final_data_2 = {'PassengerId': test.PassengerId, 'Survived': y_hat_vc_hard}\n",
    "submission_2 = pd.DataFrame(data=final_data_2)\n",
    "\n",
    "final_data_3 = {'PassengerId': test.PassengerId, 'Survived': y_hat_vc_soft}\n",
    "submission_3 = pd.DataFrame(data=final_data_3)\n",
    "\n",
    "final_data_4 = {'PassengerId': test.PassengerId, 'Survived': y_hat_vc_xgb}\n",
    "submission_4 = pd.DataFrame(data=final_data_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a1244b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission files\n",
    "submission_1.to_csv('submission_rf.csv', index = False)\n",
    "submission_2.to_csv('submission_vc_hard.csv', index = False)\n",
    "submission_3.to_csv('submission_vc_soft.csv', index = False)\n",
    "submission_4.to_csv('submission_vc_xgb.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd891dca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
